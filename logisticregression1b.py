# -*- coding: utf-8 -*-
"""LogisticRegression1b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tY9WjdihOtGfU2xDGkI4cuhAt-JK5KZx

# Reference Information & Description
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# Digesting Data

"""

#reading employee_prediction dataset

fp = r"/content/drive/MyDrive/Employeedata.csv"

df = pd.read_csv(fp)

df.head()

#Now we will get info about the data

df.info()

#We will aslo make sure there is no null data

df.isnull().sum()

#We see here there is no null values in our data ser

#Now we want to get a look at all of the data in this table statistically
#The best way to do this is using describe

df.describe()

"""# Visualizing the dataset"""

#Now I want to start visualizing the data to see what more insights we get
#Here we will look at the distribution of our columns

#sns.displot(data=df, x="Education", col="LeaveOrNot", kde=True)

columns = list(df)[:8]

df[columns].hist(figsize=(12,50),layout=(14,4))

plt.show()

"""# More Visualizations Exploring the datset"""

#Now we will look at the correlation between the data before we plot anything else

df.corr()

#Now that I have my correlation I will put it in a heatmap to better visualize it

sns.heatmap(df.corr().abs(),vmax=1,square=True,annot=True,cmap='viridis')

plt.title("Correlation between HR dataset")

plt.show()

#Now lets look at our target variable

df['LeaveOrNot'].hist()

plt.show()

#Count between True and false values
df['LeaveOrNot'].value_counts()

#Now lets visualize our categorical variables

df["City"].value_counts().plot(kind='bar',ylabel='frequency')

#Here we visualized City

#Visualized Gender
df["Gender"].value_counts().plot(kind='pie',ylabel='frequency',autopct='%1.1f%%')

#Visuaalized EverBenched
df["EverBenched"].value_counts().plot(kind='bar',ylabel='frequency')

#Visuaalized Age
df.boxplot(column='Age',vert=False)

#Visuaalized JoiningYear
df.boxplot(column='JoiningYear',vert=False)

#Visuaalized Age
df.boxplot(column='PaymentTier',vert=False)

#Visuaalized Expierence in Domain
df.boxplot(column='ExperienceInCurrentDomain',vert=False)



"""# Data Preproccessing"""

#Check data types

df.dtypes

#Check null values

df.isna().sum()

#There are no null values in this dataset so we can move forward

"""## One Hot Encoding(Input variables)"""

#Looked at column names
df.columns

#Now we need to go back and find all of our categorical column names

df.dtypes

#Since we found the categorical columns that contain a string we will put them in a list

cols = ['Education','City','Gender','EverBenched']

#Now we will call the get dummies method
#The gert dummies method One Hot Encodes
#This means that it creates a numerical representation for categorical variables
#dropfirst = True drops a column because of multicolineary effect

df = pd.get_dummies(df,columns= cols, drop_first=True)

df

"""## Label Encoding for (Target Variable)"""

#Importing my label Encoder as le
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

#Brining in my target variable to fit/transform

df['LeaveOrNot'] = le.fit_transform(df['LeaveOrNot'])

#le.classes_ breaks up the labels into an array for us
#to view to see if it got the correct labels

le.classes_

#Now lets count the values between the two labeled categories

df['LeaveOrNot'].value_counts()
#We have 3053 falses or Stayed(0)
#We have 1600 Trues or Left(1)

df

"""## Shuffle The dataset"""

#Brining in the datset to shuffle the data
from sklearn.utils import shuffle
#Shuffling the data means to randomly reorder therows of your data
#This is done to introduce randomness and remve any patternsthat might exist in the data.
#Shuffling is commonly applied when splitting the dataset into test and traing sets

df = shuffle(df)

df

"""# Splitting X and y"""

#Splitting X
#X will be our features

X = df.drop(['LeaveOrNot'], axis=1)
X

#Splitting y
#y is our prediction varible we want

y = df['LeaveOrNot']

y

"""## Balance Dataset"""

from collections import Counter

from imblearn.over_sampling import RandomOverSampler

#Summarize Class distribution
print(Counter(y))

#Define Oversampling strategy

oversample = RandomOverSampler(sampling_strategy='minority')

#fit and apply the trasform

X, y = oversample.fit_resample(X,y)

#Summarize New distribution

print(Counter(y))

"""# Normalize or Standardize Datset"""

from sklearn.preprocessing import MinMaxScaler
scaler_m = MinMaxScaler()

X = scaler_m.fit_transform(X.values)

X.shape

"""# Train/Test/Split Data"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7,test_size = .3)
#As you can see above we trained 70% of our data and tested 30% of it



"""## Modeling"""

#Imported logistic regression
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=10000,class_weight='balanced',solver='saga',C=0.2)

#Train the model
lr.fit(X_train,y_train)

#calling score method on classfiers
#measures the models performance on a given dataset
#This evaluates the models accuracy
lr.score(X_test,y_test)

#Enables us to predict the labels of the data values (X_test) on the basis of the trained model
y_pred =lr.predict(X_test)

"""## Evaluation"""

from sklearn.metrics import confusion_matrix,classification_report

cm = confusion_matrix(y_test,y_pred)
cm

print(classification_report(y_test,y_pred))

"""# Plotting Confusion Matrix"""

#Time to plot the confusion matix
import seaborn as sns
sns.heatmap(cm, annot=True,fmt='g',cmap= 'Blues')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# Plot the ROC/AUC Curve"""

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
logit_roc_auc = roc_auc_score(y_test, lr.predict(X_test))
fpr, tpr,thresholds = roc_curve(y_test, lr.predict_proba(X_test)[:,1])
plt.figure()
plt.plot(fpr,tpr, label= 'Logistic Regression (area = %0.2f)' % logit_roc_auc)
plt.plot([0,1],[0,1], 'r--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Reciever Operating Characteristic')
plt.legend(loc='lower right')
plt.savefig('Log_ROC')
plt.show()

